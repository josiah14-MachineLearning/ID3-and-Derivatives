import coconut.convenience
import pandas as pd
import numpy as np
from pandas import DataFrame
from pandas.core.groupby.generic import DataFrameGroupBy
from typing import List

spam_analysis_data = {
    'SpamId': [376,489,541,693,782,976],
    'SuspiciousWords': [True,True,True,False,False,False],
    'UnknownSender': [False,True,True,True,False,False],
    'Images': [True,False,False,True,False,False],
    'SpamClass': ["spam","spam","spam","ham","ham","ham"]
}


def entropy(
    total_records: int,
    value_frequencies: np.array,
    log_base: int = 2
) -> float =
    item_probs = value_frequencies / total_records
    -(item_probs * np.log(item_probs) / np.log(log_base)).sum()


def frame_entropy(df: DataFrame, target_feature: str) -> float =
    grouped_df = df.groupby(target_feature)
    counts = map(
        (k) -> len(grouped_df.get_group(k).index),
        grouped_df.indices.keys()
    )
    counts |> list |> np.array |> entropy$(len(df.index))


def remaining_entropy(
    original_df: DataFrame,
    target_feature: str,
    grouped_df: DataFrameGroupBy
) -> float =
    def weighted_group_entropy(df: DataFrame) -> float = (
        len(df.index)
        / len(original_df.index)
        * frame_entropy(df, target_feature)
    )
    grouped_frames = map(grouped_df.get_group, grouped_df.indices.keys()) |> list
    map(weighted_group_entropy, grouped_frames) |> list |> np.array |> .sum()


def information_gain(
    target_feature: str,
    original_entropy: float,
    original_df: DataFrame,
    grouped_df: DataFrameGroupBy
) -> float =
    original_entropy - remaining_entropy(original_df, target_feature, grouped_df)


def find_most_informative_feature(
    target_feature: str,
    df: DataFrame
) -> (float, str, DataFrameGroupBy) =
    original_entropy = frame_entropy(df, target_feature)
    def calc_IG(descriptive_feature: str) -> (float, str, DataFrameGroupBy) =
        grouped_df = df.groupby(descriptive_feature)
        (
            information_gain(target_feature, original_entropy, df, grouped_df),
            descriptive_feature,
            grouped_df
        )

    def keep_greatest_information_gain(
        acc_df: (float, str, DataFrameGroupBy),
        next_descriptive_feature: str
    ) -> (float, str, DataFrameGroupBy) =
        next_df = calc_IG(next_descriptive_feature)
        acc_df if acc_df[0] >= next_df[0] else next_df

    descriptive_features = df.drop(target_feature, axis=1).columns |> list
    descriptive_features[0] = calc_IG(descriptive_features[0])
    reduce(keep_greatest_information_gain, descriptive_features)


spam_analysis_df = pd.DataFrame(spam_analysis_data).drop('SpamId', axis=1)
spam_analysis_df |> find_most_informative_feature$("SpamClass") |> .[1:] |> print
