import coconut.convenience
import pandas as pd
import numpy as np
from pandas import DataFrame
from pandas.core.groupby.generic import DataFrameGroupBy
from typing import List

spam_analysis_data = {
    'SpamId': [376,489,541,693,782,976],
    'SuspiciousWords': [True,True,True,False,False,False],
    'UnknownSender': [False,True,True,True,False,False],
    'Images': [True,False,False,True,False,False],
    'SpamClass': ["spam","spam","spam","ham","ham","ham"]
}


def entropy(
    total_records: int,
    value_frequencies: np.array,
    log_base: int = 2
) -> float =
    def item_probability(freq) = freq / total_records
    item_probability_v = np.vectorize(item_probability)

    item_probs = item_probability_v(value_frequencies)
    -(item_probs * np.log(item_probs) / np.log(log_base)).sum()


def frame_entropy(df: DataFrame, target_feature: str) -> float =
    grouped_df = df.groupby(target_feature)

    counts = map(
        (k) -> len(grouped_df.get_group(k).index),
        grouped_df.indices.keys()
    )

    counts |> list |> np.array |> entropy$(len(df.index))


def remaining_entropy(
    original_df: DataFrame,
    target_feature: str,
    grouped_df: DataFrameGroupBy
) -> float =
    grouped_frames = list(map(grouped_df.get_group, grouped_df.indices.keys()))

    def weighted_group_entropy(df: DataFrame) -> float = (
        len(df.index)
        / len(original_df.index)
        * frame_entropy(df, target_feature)
    )

    map(weighted_group_entropy, grouped_frames) |> list |> np.array |> .sum()


spam_analysis_df = pd.DataFrame(spam_analysis_data).drop('SpamId', axis=1)
map(
    (descriptive_feature) -> remaining_entropy(
        spam_analysis_df,
        "SpamClass",
        spam_analysis_df.groupby(descriptive_feature)
    ),
    spam_analysis_df.drop('SpamClass', axis=1).columns
) |> list |> print
